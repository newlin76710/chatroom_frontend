// SongPanel.jsx
import { useEffect, useRef, useState } from "react";
import { io } from "socket.io-client";
import "./SongPanel.css";

const BACKEND = import.meta.env.VITE_BACKEND_URL || "http://localhost:10000";
const socket = io(BACKEND, { transports: ["websocket"] });

export default function SongPanel({ room, name }) {
  const [phase, setPhase] = useState("idle"); // idle | singing | recording | scoring | listening
  const [micLevel, setMicLevel] = useState(0);
  const [myScore, setMyScore] = useState(null);
  const [avgScore, setAvgScore] = useState(null);
  const [scoreCount, setScoreCount] = useState(0);
  const [scoreCountdown, setScoreCountdown] = useState(0);
  const [queue, setQueue] = useState([]);
  const [currentSinger, setCurrentSinger] = useState(null);
  const [joinedQueue, setJoinedQueue] = useState(false);
  const [listeningUrl, setListeningUrl] = useState(null);

  const localStreamRef = useRef(null);
  const audioCtxRef = useRef(null);
  const analyserRef = useRef(null);
  const dataArrayRef = useRef(null);
  const animationIdRef = useRef(null);
  const countdownRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const chunksRef = useRef([]);

  // ===== åŠ å…¥éšŠåˆ— =====
  const joinQueue = () => {
    if (phase !== "idle") return;
    socket.emit("joinQueue", { room, singer: name });
    setJoinedQueue(true);
    setPhase("singing"); 
  };

  // ===== é–‹å§‹éŒ„éŸ³ =====
  const startRecording = async () => {
    if (phase !== "singing") return;
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      localStreamRef.current = stream;

      // éº¥å…‹é¢¨éŸ³é‡åˆ†æ
      audioCtxRef.current = new AudioContext();
      const source = audioCtxRef.current.createMediaStreamSource(stream);
      analyserRef.current = audioCtxRef.current.createAnalyser();
      analyserRef.current.fftSize = 256;
      source.connect(analyserRef.current);
      dataArrayRef.current = new Uint8Array(analyserRef.current.frequencyBinCount);

      const updateMic = () => {
        analyserRef.current.getByteFrequencyData(dataArrayRef.current);
        const avg = dataArrayRef.current.reduce((a, b) => a + b, 0) / dataArrayRef.current.length;
        setMicLevel(avg / 255);
        animationIdRef.current = requestAnimationFrame(updateMic);
      };
      updateMic();

      // MediaRecorder
      chunksRef.current = [];
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (e) => chunksRef.current.push(e.data);

      mediaRecorder.onstop = async () => {
        const blob = new Blob(chunksRef.current, { type: "audio/webm" });
        const audioUrl = URL.createObjectURL(blob);
        setListeningUrl(audioUrl); 
        chunksRef.current = [];

        // è¨ˆç®—éŒ„éŸ³é•·åº¦
        const duration = await getBlobDuration(blob);

        // ä¸Šå‚³
        const formData = new FormData();
        formData.append("audio", blob, "song.webm");
        formData.append("singer", name);

        const res = await fetch(`${BACKEND}/song/upload`, { method: "POST", body: formData });
        const data = await res.json();
        console.log("ä¸Šå‚³å›å‚³", data);

        // å»£æ’­çµ¦å…¶ä»–äººæ’­æ”¾
        socket.emit("songReady", {
          room,
          singer: name,
          url: data.url,
          duration
        });

        setPhase("scoring");
        setScoreCountdown(Math.ceil(duration));
      };

      mediaRecorder.start();
      setPhase("recording");
    } catch (err) {
      console.error("ğŸ¤ éŒ„éŸ³å¤±æ•—", err);
    }
  };

  // ===== åœæ­¢éŒ„éŸ³ =====
  const stopRecording = () => {
    if (phase !== "recording") return;

    localStreamRef.current?.getTracks().forEach((t) => t.stop());
    localStreamRef.current = null;

    cancelAnimationFrame(animationIdRef.current);
    animationIdRef.current = null;
    audioCtxRef.current?.close();
    audioCtxRef.current = null;
    analyserRef.current = null;
    dataArrayRef.current = null;

    mediaRecorderRef.current?.stop();
    // ä¸è¦ç«‹åˆ»æ¸…æ‰ mediaRecorderRef.currentï¼Œä¿ç•™ onstop ä½¿ç”¨
  };

  // ===== è©•åˆ† =====
  const scoreSong = (score) => {
    if (phase !== "scoring") return;
    setMyScore(score);
    socket.emit("scoreSong", { room, score });
  };

  // ===== å€’æ•¸è¨ˆæ™‚ =====
  useEffect(() => {
    if (phase !== "scoring" || scoreCountdown <= 0) return;
    countdownRef.current = setInterval(() => {
      setScoreCountdown((s) => {
        if (s <= 1) {
          clearInterval(countdownRef.current);
          return 0;
        }
        return s - 1;
      });
    }, 1000);
    return () => clearInterval(countdownRef.current);
  }, [phase, scoreCountdown]);

  // ===== Socket ç›£è½ =====
  useEffect(() => {
    socket.on("queueUpdate", ({ queue, current }) => {
      setQueue(queue);
      if (current) setCurrentSinger(current); 
    });

    socket.on("songResult", ({ avg, count }) => {
      setAvgScore(avg);
      setScoreCount(count);
      setPhase("idle");
      setMyScore(null);
      setScoreCountdown(0);
      setJoinedQueue(false);
      setListeningUrl(null);
    });

    socket.on("playSong", ({ url, duration }) => {
      setListeningUrl(url);
      setScoreCountdown(Math.ceil(duration));
      setPhase("scoring");
    });

    socket.on("update-room-phase", ({ phase: newPhase, singer }) => {
      setPhase(newPhase);
      if (singer) setCurrentSinger(singer); 
    });

    const handleUnload = () => {
      stopRecording();
      if (joinedQueue) socket.emit("leaveQueue", { room, singer: name });
    };
    window.addEventListener("beforeunload", handleUnload);

    return () => {
      socket.off("queueUpdate");
      socket.off("songResult");
      socket.off("playSong");
      socket.off("update-room-phase");
      window.removeEventListener("beforeunload", handleUnload);
    };
  }, [name, phase, joinedQueue]);

  const getBlobDuration = (blob) =>
    new Promise((resolve) => {
      const tempAudio = document.createElement("audio");
      tempAudio.src = URL.createObjectURL(blob);
      tempAudio.addEventListener("loadedmetadata", () => resolve(tempAudio.duration));
    });

  return (
    <div className="song-panel">
      <h4>ğŸ¤ å”±æ­Œå€</h4>
      <div className="status">
        ç•¶å‰: {currentSinger || "--"} / æˆ‘çš„ç‹€æ…‹: {phase}
      </div>

      <div className="controls">
        <button onClick={joinQueue} disabled={phase !== "idle"}>åŠ å…¥éšŠåˆ—</button>
        <button onClick={startRecording} disabled={phase !== "singing" || currentSinger !== name}>é–‹å§‹éŒ„éŸ³</button>
        <button onClick={stopRecording} disabled={phase !== "recording"}>åœæ­¢éŒ„éŸ³</button>
      </div>

      {(phase === "recording" || phase === "scoring") && (
        <div className="mic-meter">
          {phase === "recording" && <div className="mic-bar" style={{ width: `${micLevel * 100}%` }} />}
        </div>
      )}

      {phase === "scoring" && (
        <div className="score-container">
          <div className="score-countdown">è©•åˆ†å€’æ•¸ï¼š{scoreCountdown} ç§’</div>
          <div className="score-stars">
            {[1, 2, 3, 4, 5].map((n) => (
              <span key={n} className={myScore >= n ? "selected" : ""} onClick={() => scoreSong(n)}>â˜…</span>
            ))}
          </div>
        </div>
      )}

      {listeningUrl && <div>
        <audio src={listeningUrl} controls autoPlay />
      </div>}

      <div className="avg-score">
        ä¸Šä¸€ä½å¹³å‡ï¼š{avgScore !== null ? avgScore.toFixed(1) : "--"} åˆ† â­ï¼ˆ{scoreCount} äººï¼‰
      </div>

      <div className="queue-list">
        ç•¶å‰å”±æ­Œè€…ï¼š{currentSinger || "--"}<br />
        æ’éšŠåå–®ï¼š{queue.length ? queue.join(" / ") : "--"}
      </div>
    </div>
  );
}
